
     Program POST-PROC v.7.2 starts on 27Mar2024 at 22:23:34 

     This program is part of the open-source Quantum ESPRESSO suite
     for quantum simulation of materials; please cite
         "P. Giannozzi et al., J. Phys.:Condens. Matter 21 395502 (2009);
         "P. Giannozzi et al., J. Phys.:Condens. Matter 29 465901 (2017);
         "P. Giannozzi et al., J. Chem. Phys. 152 154105 (2020);
          URL http://www.quantum-espresso.org", 
     in publications or presentations arising from this work. More details at
     http://www.quantum-espresso.org/quote

     Parallel version (MPI & OpenMP), running on       1 processor cores
     Number of MPI processes:                 1
     Threads/MPI process:                     1

     MPI processes distributed on     1 nodes
     1969141 MiB available memory on the printing compute node when the environment starts
 

     Reading xml data from directory:

     ./diamond.save/

     **************************************************************************
     Initializing libbeef V0.1.2 with the BEEF-vdW functional.
     Citation: Wellendorff et al., PRB 85, 235149 (2012).
     **************************************************************************

     file C.pbe-n-kjpaw_psl.1.0.0.UPF: wavefunction(s)  2S 2P renormalized

     IMPORTANT: XC functional enforced from input :
     Exchange-correlation= BEEF
                           (   1   4  43  14   2   0   0)
     Any further DFT definition will be discarded
     Please, verify this is what you really want

 
     G-vector sticks info
     --------------------
     sticks:   dense  smooth     PW     G-vecs:    dense   smooth      PW
     Sum        1273    1005    301                34049    24303    3959
 
     Using Slab Decomposition
 

     Check: negative core charge=   -0.000014


     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
     %                                                                      %
     % You are using vdW-DF, which was implemented by the Thonhauser group. %
     % Please cite the following two papers that made this development      %
     % possible and the two reviews that describe the various versions:     %
     %                                                                      %
     %   T. Thonhauser et al., PRL 115, 136402 (2015).                      %
     %   T. Thonhauser et al., PRB 76, 125112 (2007).                       %
     %   K. Berland et al., Rep. Prog. Phys. 78, 066501 (2015).             %
     %   D.C. Langreth et al., J. Phys.: Condens. Matter 21, 084203 (2009). %
     %                                                                      %
     % If you are calculating stress with vdW-DF, please also cite:         %
     %                                                                      %
     %   R. Sabatini et al., J. Phys.: Condens. Matter 24, 424209 (2012).   %
     %                                                                      %
     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
     %                                                                      %
     %  vdW-DF NEWS:                                                        %
     %                                                                      %
     %  * vdW-DF3 is now available. DOI: 10.1021/acs.jctc.0c00471           %
     %    use with input_dft = 'vdW-DF3-opt1' or 'vdW-DF3-opt2'             %
     %                                                                      %
     %  * Unscreened and range-separated hybrid vdW-DF-cx functionals       %
     %    DOI: 10.1063/1.4986522 and 10.1088/1361-648X/ac2ad2               %
     %    use with input_dft = 'vdW-DF-cx0'    and 'vdW-DF-ahcx'            %
     %  * Unscreened and range-separated hybrid vdW-DF2-b86r functionals    %
     %    DOI: 10.1063/1.4986522 and DOI: 10.1103/PhysRevX.12.041003        %
     %    use with input_dft = 'vdW-DF2-br0' and 'vdW-DF2-ahbr'             %
     %                                                                      %
     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



     Calling punch_plot, plot_num =   7

     Plotting k_point =   1  band =126

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
     Error in routine local_dos (1):
     wrong band specified
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

     stopping ...
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
------------------------------------------------------------
A process or daemon was unable to complete a TCP connection
to another process:
  Local host:    trace23
  Remote host:   trace24
This is usually caused by a firewall on the remote host. Please
check that any firewall (e.g., iptables) has been disabled and
try again.
------------------------------------------------------------
